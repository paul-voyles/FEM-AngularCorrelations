{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEM -Example\n",
    "\n",
    "\n",
    "## 0.0 Introduction\n",
    "This notebook shows you how to perform a fluctuation electron mircoscopy (FEM) analysis for a Zr-Cu-Al Sample.  Most of this analysis is done in [pyXEM](https://github.com/pyxem/pyxem) version 13.3. As a package in development there might be some breaking changes with each sucessive itereation.  pyxXEM is an extension of [hyperspy](https://hyperspy.org/hyperspy-doc/current/index.html) so reading some of their documentation is a good place to start in many cases. \n",
    "\n",
    "In this notebook we will focus on calculating $V_\\Omega$ which can be defined as follows.  The first part describes the varience while the second part describes the possion noise correction.\n",
    "\n",
    "Equation 1:   $V_\\Omega = \\frac{<<I>_\\theta^2 >_r}{<<I>_{\\theta, r}>^2 } -1 - \\frac{gain}{<\\Sigma_\\theta(I)>_r}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hyperspy.api as hs\n",
    "import glob\n",
    "from skimage.measure import EllipseModel\n",
    "from hyperspy.signal import BaseSignal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Loading and Visualizing the Data \n",
    "\n",
    "The example data is a 10x10 STEM dataset with large spacing betweent the probe positions. A HAADF image is also included to use as a reference for the thickness filtering.\n",
    "\n",
    "The data is currently in the `.hspy` format which is hyperspy's open hdf5 file format.  Hyperspy can load many different file types, however, a complete list is given [here](https://hyperspy.org/hyperspy-doc/current/user_guide/io.html#supported-formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = glob.glob('Data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = hs.load(signals[0], signal_type=\"electron_diffraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can see information about the size of the set of diffraction patterns. \n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the plotting backend to make it intereactive\n",
    "%matplotlib inline\n",
    "signal.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Calibrating the Diffraction Patterns\n",
    "\n",
    "The following methods below are some methods useful for determing the center of some diffraction pattern if there is a beam stop included in the data.  The intent is to include these methods into pyxem (see https://github.com/pyxem/pyxem/pull/769) but they currently are not included.  If you don't have a beam stop I would recommend using the [`diffraction_signal.center_direct_beam()`](https://github.com/pyxem/pyxem/blob/de140bb5dc19c0e9d1a91a725c656c2bd2c056d0/pyxem/signals/diffraction2d.py#L698) method.\n",
    "\n",
    "The method below also provides some ability to correct for ellipticty in the diffraction pattern. \n",
    "\n",
    "In general the best way to see if there is any ellipticity in a diffraction pattern is to look at the polar unwrapped diffraction pattern which we have done below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_positions(signal,\n",
    "                      mask=None,\n",
    "                      num_points=5000,\n",
    "                      ):\n",
    "    \"\"\" Gets the top num_points pixels in the dataset.\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    signal: BaseSignal\n",
    "        The signal which we want to find the max positions for.\n",
    "    mask: np.array\n",
    "        A mask to be applied to the data for values to ignore\n",
    "    num_points: int\n",
    "        The number of points to be\n",
    "    \"\"\"\n",
    "    if isinstance(signal, BaseSignal):\n",
    "        data = signal.data\n",
    "    else:\n",
    "        data = signal\n",
    "    i_shape = np.shape(data)\n",
    "    flattened_array = data.flatten()\n",
    "    if mask is not None:\n",
    "        flattened_mask = mask.flatten()\n",
    "        flattened_array[flattened_mask]=0\n",
    "    # take top 5000 points make sure exclude zero beam\n",
    "    indexes = np.argsort(flattened_array)\n",
    "    cords = np.array([np.floor_divide(indexes[-num_points:], i_shape[1]),\n",
    "             np.remainder(indexes[-num_points:], i_shape[1])]) # [x axis (row),y axis (col)]\n",
    "    return cords.T\n",
    "\n",
    "def determine_ellipse(signal,\n",
    "                      mask=None,\n",
    "                      num_points=1000,\n",
    "                      **kwargs,\n",
    "                      ):\n",
    "    \"\"\"\n",
    "    This method starts by taking some number of points which are the most intense\n",
    "    in the signal.  It then takes those points and guesses some starting parameters\n",
    "    for the `get_ellipse_model_ransac_single_frame` function. From there it will try\n",
    "    to determine the ellipse parameters.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    signal: Signal2D\n",
    "        The signal of interest\n",
    "    mask: Array-like\n",
    "        The mask to be applied to the data.  All of the masked values are ignored\n",
    "    num_points: int\n",
    "        The number of points to consider\n",
    "    guess_starting_params: bool\n",
    "        If True then the starting parameters will be guessed based on the points determined.\n",
    "    **kwargs:\n",
    "        Any other keywords for ` get_ellipse_model_ransac_single_frame`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    center: (x,y)\n",
    "        The center of the diffraction pattern\n",
    "    affine:\n",
    "        The affine transformation to make the diffraction pattern circular.\n",
    "    \"\"\"\n",
    "    pos = get_max_positions(signal,\n",
    "                            mask=mask,\n",
    "                            num_points=num_points)\n",
    "    e = EllipseModel()\n",
    "    converge = e.estimate(data=pos)\n",
    "    el = e\n",
    "    if el is not None:\n",
    "        affine = ellipse_to_affine(el.params[3],el.params[2], el.params[4])\n",
    "        center = (el.params[0],el.params[1])\n",
    "        return center, affine\n",
    "    else:\n",
    "        print(\"Ransac Ellipse detection did not converge\")\n",
    "        return None\n",
    "\n",
    "def ellipse_to_affine(major, minor, rot):\n",
    "    if major < minor:\n",
    "        print(\"major<minor\")\n",
    "        temp = major\n",
    "        major = minor\n",
    "        minor = temp\n",
    "        rot=rot+(np.pi/2)\n",
    "\n",
    "    Q = [[np.cos(rot), -np.sin(rot), 0],\n",
    "         [np.sin(rot), np.cos(rot), 0],\n",
    "         [0, 0, 1]]\n",
    "    S = [[1, 0, 0],\n",
    "         [0, major / minor, 0],\n",
    "         [0, 0, 1]]\n",
    "    C = np.matmul(np.matmul(Q, S), np.transpose(Q))\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center, affine =determine_ellipse(signal.sum())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.beam_energy=200\n",
    "signal.unit=\"k_nm^-1\"\n",
    "signal.set_ai(center= center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.get_azimuthal_integral2d(npt=100).sum().isig[:,2.:8.].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Calculating the Variance\n",
    "\n",
    "From this point calcualating the variance is quite easy.  The `get_varaince` method can easily calculate the variance using the Azimuthal_Integrator set above with the `set_ai` method. \n",
    "\n",
    "Note that the DQE parameter isn't really the best description for that parameter.  A more accureate description is the gain of the detector.  It is used to count the number of electrons which hit the detector.  That is then used for the Possion Noise Correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(signal.get_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.get_variance(npt=50,dqe=4.2, radial_range=(3.0,5.75)).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Thickness Filtering \n",
    "\n",
    "Another consideration is often the thickness of the sample.  For this sample (which is deposited as a thin film) variations of thickness are minimal.  For samples which have much more variation of thickness, the $V_\\Omega$ calculcation will mostly just measure the variations due to thickness rather than strucuture. \n",
    "\n",
    "As $V_\\Omega$ measures spatial variance it is very sensitive to thickness changes in the sample. \n",
    "\n",
    "Thickness filtering is not currently built into `pyxem` but preforming some thickness filtering isn't terrribly difficult using the framework available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have already saved the haadf along side the dataset. We can see this here...\n",
    "signal.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haadf = hs.signals.Signal2D(signal.metadata.HAADF.intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness = ((haadf -26265)/440.46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thickness_filter(signal, thickness, bins):\n",
    "    masks = [np.logical_and(bins[i]<thickness, bins[i+1]>thickness) for i in range(len(bins)-1)]\n",
    "    filtered = [hs.signals.Signal2D(signal.data[m.data,:,:]) for m in masks]\n",
    "    for f in filtered:\n",
    "        f.set_signal_type(\"electron_diffraction\")\n",
    "        f.axes_manager.signal_axes= signal.axes_manager.signal_axes\n",
    "        f.metadata = signal.metadata\n",
    "    return filtered, thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(np.min(thickness, axis=(0,1)), np.max(thickness, axis=(0,1)), num=2+1)\n",
    "filtered, thickness = thickness_filter(signal, thickness, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = [f.get_variance(npt=50, dqe=4.2, radial_range=(3.0, 5.7)) for f in filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs.plot.plot_spectra(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Example \n",
    "## (WARNING! This might not work in Binder because of Memory Constraints)\n",
    "\n",
    "In this case we don't have quite enough data to accurately measure the stucuture of the sample.  100 diffraction patterns split into different thicknesses isn't quite statistically rigorous.  Ideally the variance curves would be identical for each thickness. Simply we just don't have enough data to calculate what we are interested in calculating.\n",
    "\n",
    "\n",
    "Below we have loaded 10 seperate positions each with a 10x10 dataset collected.  This is starting to get to enough data to run one of these experiments.  That being said, if you have a sample with a lot of thickness variation then you will need to probe a larger area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = glob.glob('Data/*')\n",
    "signals = hs.load(signals, signal_type=\"electron_diffraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in signals:\n",
    "    center, affine =determine_ellipse(s.sum())\n",
    "    s.beam_energy=200\n",
    "    s.unit=\"k_nm^-1\"\n",
    "    s.set_ai(center= center)\n",
    "    haadf = hs.signals.Signal2D(s.metadata.HAADF.intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = [s.get_variance(npt=50, dqe=4.2, radial_range=(3.0, 5.7) )for s in signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs =plt.subplots(1,1,figsize=(10,5))\n",
    "\n",
    "error = np.std([v.data for v in var])/np.sqrt(10)\n",
    "mean_val = np.mean(var).data\n",
    "axs.plot(np.linspace(3.0,5.7,50), mean_val)\n",
    "axs.fill_between(np.linspace(3.0,5.7,50),mean_val-error, mean_val+error, alpha=.2)\n",
    "axs.set(xlim=(3.0,5.7), ylabel=\"Variance\", xlabel=\"k, nm $^{-1}$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Methods for Calculating Variance\n",
    "\n",
    "\n",
    "Additional methods for calculating varaince are also available.  The naming standard follows the 2010 Kelton paper[1]\n",
    "\n",
    "    [1] Daulton, T. L et al, Ultramicroscopy, 110(10), 1279â€“1289, https://doi.org/10.1016/j.ultramic.2010.05.010\n",
    "        Nanobeam diffraction fluctuation electron microscopy technique for structural characterization of disordered\n",
    "        materials-Application to Al88-xY7Fe5Tix metallic glasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs =plt.subplots(1,3,figsize=(15,5))\n",
    "gain=4.2\n",
    "for method,ax in zip([\"Omega\", \"r\", \"re\"],axs):\n",
    "    var = [s.get_variance(npt=50, dqe=gain, radial_range=(3.0, 5.7), method=method)for s in signals]\n",
    "    error = np.std([v.data for v in var])/np.sqrt(10)\n",
    "    mean_val = np.mean(var).data\n",
    "    ax.plot(np.linspace(3.0,5.7,50), mean_val)\n",
    "    ax.fill_between(np.linspace(3.0,5.7,50),mean_val-error, mean_val+error, alpha=.2)\n",
    "    ax.set(xlim=(3.0,5.7), ylabel=\"Variance\", xlabel=\"k, nm $^{-1}$\")\n",
    "    ax.title.set_text(method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "developmental",
   "language": "python",
   "name": "developmental"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
